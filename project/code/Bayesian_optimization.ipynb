{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf3e50c9",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-03-20T13:11:51.876417Z",
     "iopub.status.busy": "2023-03-20T13:11:51.875792Z",
     "iopub.status.idle": "2023-03-20T13:11:51.897171Z",
     "shell.execute_reply": "2023-03-20T13:11:51.895079Z"
    },
    "papermill": {
     "duration": 0.034444,
     "end_time": "2023-03-20T13:11:51.900985",
     "exception": false,
     "start_time": "2023-03-20T13:11:51.866541",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/pubg-finish-placement-prediction/train_V2.csv\n",
      "/kaggle/input/pubg-finish-placement-prediction/test_V2.csv\n",
      "/kaggle/input/pubg-finish-placement-prediction/sample_submission_V2.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9e04bf6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T13:11:51.915115Z",
     "iopub.status.busy": "2023-03-20T13:11:51.914675Z",
     "iopub.status.idle": "2023-03-20T13:11:51.945418Z",
     "shell.execute_reply": "2023-03-20T13:11:51.944003Z"
    },
    "papermill": {
     "duration": 0.041622,
     "end_time": "2023-03-20T13:11:51.948707",
     "exception": false,
     "start_time": "2023-03-20T13:11:51.907085",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_group_place(df, matchId) :\n",
    "    # 각 match 선택\n",
    "    match_data = df[df['matchId'].values == matchId]\n",
    "    num = match_data['maxPlace'].mean()\n",
    "    \n",
    "    if match_data['groupId'].nunique() == 1 : \n",
    "        gid = match_data['groupId'].values[0]\n",
    "        final_dictionary.update({gid : 0})\n",
    "        return \n",
    "    \n",
    "    elif match_data['groupId'].nunique() == 2 :\n",
    "        gids = match_data['groupId'].unique()\n",
    "        g1 = gids[0]\n",
    "        g2 = gids[1]\n",
    "        g1_kills = match_data[match_data['groupId'].values == g1]['kills'].sum()\n",
    "        if g1_kills == len(match_data[match_data['groupId'].values == g2]) : \n",
    "            final_dictionary.update({g1 : 1,\n",
    "                                     g2 : 0})\n",
    "        else : \n",
    "            final_dictionary.update({g1 : 0,\n",
    "                                     g2 : 1})\n",
    "        return \n",
    "        \n",
    "    # solo or not \n",
    "    mtype = match_data['matchType'].iloc[0]\n",
    "    \n",
    "    # empty  \n",
    "    Maxplace = match_data.iloc[0]['maxPlace']\n",
    "    Numgroups = match_data.iloc[0]['numGroups']\n",
    "    t = Maxplace - Numgroups\n",
    "    pivot = int(np.round((Maxplace - t)/(t+1)))\n",
    "    indices = []\n",
    "    for i in range(1, t+1) : \n",
    "        indices.append(i*pivot)\n",
    "    \n",
    "    # kill별로 sort\n",
    "    match_data = match_data.sort_values(by = ['kills', 'killPlace'])\n",
    "    match_data = match_data[['kills', 'groupId', 'killPlace']]\n",
    "\n",
    "    # 해당 kill에 해당하는 user가 1명인 경우 제외   \n",
    "    kills_values = match_data['kills'].value_counts()\n",
    "    kills_unique = kills_values[kills_values.values == 1].index.tolist()\n",
    "    kills_unique_user = match_data[match_data['kills'].isin(kills_unique)]\n",
    "    \n",
    "    kill_type = kills_values.index\n",
    "    \n",
    "    ###\n",
    "    if (match_data['kills'].value_counts() == 1).all() : \n",
    "        rank_dict_lst = match_data.groupby('groupId')['kills'].max().sort_values(ascending = False).index.tolist()\n",
    "    \n",
    "    else : \n",
    "        if 'solo' not in mtype : \n",
    "            match_data = match_data[~match_data['kills'].isin(kills_unique)]\n",
    "            match_data = match_data.sort_values(by = ['kills', 'killPlace'], ascending = True)\n",
    "\n",
    "        if 'solo' in mtype :\n",
    "            group_lst = []\n",
    "            kill_type = sorted(kill_type, reverse = True)\n",
    "\n",
    "            for kt in kill_type :\n",
    "                kill_data = match_data[match_data['kills'] == kt]\n",
    "                kill_data = kill_data.sort_values(by = 'killPlace')\n",
    "                group_lst =  group_lst + list(kill_data['groupId']) \n",
    "\n",
    "\n",
    "        kill_0 = match_data[match_data['kills'] == kill_type[0]][['killPlace', 'groupId']]\n",
    "        kill_0 = kill_0.drop_duplicates(['groupId'])\n",
    "        kill_0 = kill_0['groupId'].values\n",
    "\n",
    "        loc_dict = {}\n",
    "        rank_dict = {}    \n",
    "        \n",
    "        cetain_lst = []\n",
    "        for i in range(len(kill_0)) : \n",
    "            groupId = kill_0[i]\n",
    "            rank_dict[i] = [groupId]\n",
    "            loc_dict[groupId] = i\n",
    "\n",
    "        for kt in kill_type[1:] :\n",
    "            kill_1 = match_data[match_data['kills'] == kt][['killPlace', 'groupId']]\n",
    "            kill_1 = kill_1.drop_duplicates(['groupId'])\n",
    "            kill_1 = kill_1['groupId'].values\n",
    "\n",
    "            for i in range(len(kill_1)) : \n",
    "                cur_group = kill_1[i]\n",
    "                if cur_group in loc_dict : \n",
    "                    continue \n",
    "                else : \n",
    "                    # upper bound \n",
    "                    refer_lst = kill_1[i:]\n",
    "                    check_lst = [1 if r in loc_dict else 0 for r in refer_lst]\n",
    "                    if any(check_lst) : \n",
    "                        r_index = check_lst.index(1)\n",
    "                        r = loc_dict[refer_lst[r_index]]\n",
    "                    else : \n",
    "                        for key, values in rank_dict.items() : \n",
    "                            if len(values) == 0 : \n",
    "                                r = key \n",
    "                                break\n",
    "                            else :\n",
    "                                r = Numgroups//2\n",
    "\n",
    "                    # lower bound \n",
    "                    refer_lst = kill_1[:i]\n",
    "                    check_lst = [1 if r in loc_dict else 0 for r in refer_lst]\n",
    "                    if any(check_lst) : \n",
    "                        l_index = max([i for i in range(len(check_lst)) if check_lst[i] == 1])\n",
    "                        l = loc_dict[refer_lst[l_index]]\n",
    "                    else : \n",
    "                        l = 0\n",
    "\n",
    "                    if (l+r)/2 in rank_dict : \n",
    "                        rank_dict[(l+r)/2].append(cur_group)\n",
    "                    else : \n",
    "                        rank_dict[(l+r)/2] = [cur_group]\n",
    "                    loc_dict[cur_group] = (l+r)/2\n",
    "\n",
    "\n",
    "        rank_dict_lst = sorted(rank_dict.items())\n",
    "        rank_dict_lst = [x[1] for x in rank_dict_lst]\n",
    "        rank_dict_lst = sum(rank_dict_lst, [])\n",
    "\n",
    "        for ku in kills_unique : \n",
    "            group_name = kills_unique_user[kills_unique_user['kills'] == ku]['groupId'].values[0]\n",
    "            if group_name not in rank_dict_lst : \n",
    "                rank_dict_lst = [group_name] + rank_dict_lst\n",
    "    rank_dict_lst_df = pd.DataFrame(rank_dict_lst)\n",
    "    \n",
    "    winPlace = np.linspace(0, 1, num = int(num), endpoint = True).tolist()\n",
    "    winPlace = list(reversed(winPlace))\n",
    "    remove_lst = [] \n",
    "    for idx in indices :\n",
    "        remove_lst.append(winPlace[idx])\n",
    "        \n",
    "    for val in remove_lst : \n",
    "        if val in winPlace : \n",
    "            winPlace.remove(val)\n",
    "        \n",
    "    rank_dict_lst_df['pred_winPlace'] = pd.Series(winPlace)\n",
    "    \n",
    "    pred_dict = rank_dict_lst_df.set_index([0]).to_dict()['pred_winPlace']\n",
    "    final_dictionary.update(pred_dict)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbc09e5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T13:11:51.963136Z",
     "iopub.status.busy": "2023-03-20T13:11:51.962693Z",
     "iopub.status.idle": "2023-03-20T13:11:52.014444Z",
     "shell.execute_reply": "2023-03-20T13:11:52.013049Z"
    },
    "papermill": {
     "duration": 0.063324,
     "end_time": "2023-03-20T13:11:52.018065",
     "exception": false,
     "start_time": "2023-03-20T13:11:51.954741",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocessing_func(df) : \n",
    "    df.drop(['killPoints', 'rankPoints', 'winPoints'], axis = 1, inplace = True)\n",
    "    \n",
    "    df['assists_mean'] = df.groupby('groupId')['assists'].transform('mean')\n",
    "    df['assists_mean_rank'] = df.groupby('matchId')['assists_mean'].rank(pct = True)\n",
    "    df['assists_max'] = df.groupby('groupId')['assists'].transform('max')\n",
    "    df['assists_rank'] = df.groupby('matchId')['assists'].rank(pct = True)\n",
    "    df['assists_group_rank'] = df.groupby('matchId')['assists_mean'].rank(pct = True)\n",
    "    df['assists'] = [3 if x >= 3 else x for x in df['assists']]\n",
    "    \n",
    "    df['boosts_mean'] = df.groupby('groupId')['boosts'].transform('mean')\n",
    "    df['boosts_mean_rank'] = df.groupby('matchId')['boosts_mean'].rank(pct = True)\n",
    "    df['boosts_max'] = df.groupby('groupId')['boosts'].transform('max')\n",
    "    df['boosts_rank'] = df.groupby('matchId')['boosts'].rank(pct = True)\n",
    "    df['boosts'] = [8 if x >= 8 else x for x in df['boosts']]\n",
    "    \n",
    "    df['damageDealt_mean'] = df.groupby('groupId')['damageDealt'].transform('mean')\n",
    "    df['damageDealt_mean_rank'] = df.groupby('matchId')['damageDealt_mean'].rank(pct = True)\n",
    "    df['damageDealt_max'] = df.groupby('groupId')['damageDealt'].transform('max')\n",
    "    df['damageDealt_rank'] = df.groupby('matchId')['damageDealt'].rank(pct = True)\n",
    "    df['damageDealt'] = [923.9 if x >= 923.9 else x for x in df['damageDealt']]\n",
    "    \n",
    "    df['DBNOs_mean'] = df.groupby('groupId')['DBNOs'].transform('mean')\n",
    "    df['DBNOs_mean_rank'] = df.groupby('matchId')['boosts_mean'].rank(pct = True)\n",
    "    df['DBNOs_max'] = df.groupby('groupId')['DBNOs'].transform('max')\n",
    "    df['DBNOs_rank'] = df.groupby('matchId')['DBNOs'].rank(pct = True)\n",
    "    df['DBNOs'] = [6 if x >= 6 else x for x in df['DBNOs']]\n",
    "    \n",
    "    df['headshotKills_mean'] = df.groupby('groupId')['headshotKills'].transform('mean')\n",
    "    df['headshotKills_mean_rank'] = df.groupby('matchId')['headshotKills_mean'].rank(pct = True)\n",
    "    df['headshotKills_max'] = df.groupby('groupId')['headshotKills'].transform('max')\n",
    "    df['headshotKills_rank'] = df.groupby('matchId')['headshotKills'].rank(pct = True)\n",
    "    df['headshotKills'] = [3 if x >= 3 else x for x in df['headshotKills']]\n",
    "    \n",
    "    df['heals_mean'] = df.groupby('groupId')['heals'].transform('mean')\n",
    "    df['heals_mean_rank'] = df.groupby('matchId')['heals_mean'].rank(pct = True)\n",
    "    df['heals_max'] = df.groupby('groupId')['heals'].transform('max')\n",
    "    df['heals_rank'] = df.groupby('matchId')['heals'].rank(pct = True)\n",
    "    df['heals'] = [15 if x >= 15 else x for x in df['heals']]\n",
    "    \n",
    "    df['kills_mean'] = df.groupby('groupId')['kills'].transform('mean')\n",
    "    df['kills_mean_rank'] = df.groupby('matchId')['kills_mean'].rank(pct = True)\n",
    "    df['kills_max'] = df.groupby('groupId')['kills'].transform('max')\n",
    "    df['kills_rank'] = df.groupby('matchId')['kills'].rank(pct = True)\n",
    "    df['kills'] = [8 if x >= 8 else x for x in df['kills']]\n",
    "    \n",
    "    df['killStreaks_mean'] = df.groupby('groupId')['killStreaks'].transform('mean')\n",
    "    df['killStreaks_mean_rank'] = df.groupby('matchId')['killStreaks_mean'].rank(pct = True)\n",
    "    df['killStreaks_max'] = df.groupby('groupId')['killStreaks'].transform('max')\n",
    "    df['killStreaks_rank'] = df.groupby('matchId')['killStreaks'].rank(pct = True)\n",
    "    df['killStreaks'] = [3 if x >= 3 else x for x in df['killStreaks']]\n",
    "    \n",
    "    df['longestKill_mean'] = df.groupby('groupId')['longestKill'].transform('mean')\n",
    "    df['longestKill_mean_rank'] = df.groupby('matchId')['longestKill_mean'].rank(pct = True)\n",
    "    df['longestKill_max'] = df.groupby('groupId')['longestKill'].transform('max')\n",
    "    df['longestKill_rank'] = df.groupby('matchId')['longestKill'].rank(pct = True)\n",
    "    df['longestKill'] = [3 if x >= 3 else x for x in df['longestKill']]\n",
    "    \n",
    "    df['revives_mean'] = df.groupby('groupId')['revives'].transform('mean')\n",
    "    df['revives_mean_rank'] = df.groupby('matchId')['revives_mean'].rank(pct = True)\n",
    "    df['revives_max'] = df.groupby('groupId')['revives'].transform('max')\n",
    "    df['revives_rank'] = df.groupby('matchId')['revives'].rank(pct = True)\n",
    "    df['revives'] = [2.0 if x >= 2.0 else x for x in df['revives']]\n",
    "    \n",
    "    df['roadKills_mean'] = df.groupby('groupId')['roadKills'].transform('mean')\n",
    "    df['roadKills_mean_rank'] = df.groupby('matchId')['roadKills_mean'].rank(pct = True)\n",
    "    df['roadKills_max'] = df.groupby('groupId')['roadKills'].transform('max')\n",
    "    df['roadKills_rank'] = df.groupby('matchId')['roadKills'].rank(pct = True)\n",
    "    df['roadKills'] = [3 if x >= 3 else x for x in df['roadKills']]\n",
    "    \n",
    "    df['swimDistance_mean'] = df.groupby('groupId')['swimDistance'].transform('mean')\n",
    "    df['swimDistance_mean_rank'] = df.groupby('matchId')['swimDistance_mean'].rank(pct = True)\n",
    "    df['swimDistance_max'] = df.groupby('groupId')['swimDistance'].transform('max')\n",
    "    df['swimDistance_rank'] = df.groupby('matchId')['swimDistance'].rank(pct = True)\n",
    "    df['swimDistance'] = [193.2 if x >= 193.2 else x for x in df['swimDistance']]\n",
    "    \n",
    "    df['teamKills_mean'] = df.groupby('groupId')['teamKills'].transform('mean')\n",
    "    df['teamKills_mean_rank'] = df.groupby('matchId')['teamKills_mean'].rank(pct = True)\n",
    "    df['teamKills_max'] = df.groupby('groupId')['teamKills'].transform('max')\n",
    "    df['teamKills_rank'] = df.groupby('matchId')['teamKills'].rank(pct = True)\n",
    "    df['teamKills'] = [1 if x >= 1 else x for x in df['teamKills']]\n",
    "    \n",
    "    df['walkDistance_mean'] = df.groupby('groupId')['walkDistance'].transform('mean')\n",
    "    df['walkDistance_mean_rank'] = df.groupby('matchId')['walkDistance_mean'].rank(pct = True)\n",
    "    df['walkDistance_max'] = df.groupby('groupId')['walkDistance'].transform('max')\n",
    "    df['walkDistance_rank'] = df.groupby('matchId')['walkDistance'].rank(pct = True)\n",
    "    df['walkDistance'] = [4834.0 if x >= 4834.0 else x for x in df['walkDistance']]\n",
    "    \n",
    "    df['weaponsAcquired_mean'] = df.groupby('groupId')['weaponsAcquired'].transform('mean')\n",
    "    df['weaponsAcquired_mean_rank'] = df.groupby('matchId')['weaponsAcquired_mean'].rank(pct = True)\n",
    "    df['weaponsAcquired_max'] = df.groupby('groupId')['weaponsAcquired'].transform('max')\n",
    "    df['weaponsAcquired_rank'] = df.groupby('matchId')['weaponsAcquired'].rank(pct = True)\n",
    "    df['weaponsAcquired'] = [12 if x >= 12 else x for x in df['weaponsAcquired']]\n",
    "    \n",
    "    df['playersJoined'] = df.groupby('matchId')['matchId'].transform('count')\n",
    "    df['totalDistance'] = df['walkDistance'] + df['rideDistance'] + df['swimDistance']    \n",
    "    df['playersInGroup'] = df.groupby('groupId')['Id'].transform('count')  \n",
    "    df['BoostsandHeals'] = df['boosts'] + df['heals']\n",
    "    df['groupBoostsAndHeals'] = df['boosts_mean'] + df['heals_mean']\n",
    "    df['groupKillplace'] = df.groupby('matchId')['kills_mean'].rank(pct = True)\n",
    "    df['groupVehicleDestroys'] = df.groupby('groupId')['vehicleDestroys'].transform('mean')\n",
    "    df['headshotRatio'] = [0 if y == 0 else x/y for x, y in zip(df['headshotKills'], df['kills'])]\n",
    "    df['killStreaks1'] = [4 if x >= 4 else x for x in df['killStreaks']]\n",
    "    df['swim_rank'] = df.groupby('matchId')['swimDistance'].rank(pct = True)\n",
    "    \n",
    "    df['walk/kills_rank'] = df['walkDistance_rank'] / df['kills_rank']\n",
    "    df['kills/walk_rank'] = df['kills_rank'] / df['walkDistance_rank']\n",
    "    \n",
    "    return df\n",
    "\n",
    "def reduce_mem_usage(df):\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acb596d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T13:11:52.032883Z",
     "iopub.status.busy": "2023-03-20T13:11:52.032479Z",
     "iopub.status.idle": "2023-03-20T13:11:52.044038Z",
     "shell.execute_reply": "2023-03-20T13:11:52.042449Z"
    },
    "papermill": {
     "duration": 0.023179,
     "end_time": "2023-03-20T13:11:52.047410",
     "exception": false,
     "start_time": "2023-03-20T13:11:52.024231",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def postprocessing_func(df, m) : \n",
    "    match_data = df[df['matchId'].values == m]\n",
    "    num = match_data['maxPlace'].values[0]\n",
    "    \n",
    "    # empty  \n",
    "    Maxplace = match_data.iloc[0]['maxPlace']\n",
    "    Numgroups = match_data.iloc[0]['numGroups']\n",
    "    t = Maxplace - Numgroups\n",
    "    pivot = np.int(np.round((Maxplace - t)/(t+1)))\n",
    "    indices = []\n",
    "    for i in range(1, t+1) : \n",
    "        indices.append(i*pivot)\n",
    "        \n",
    "    match_data = match_data[['groupId', 'winPlacePercPred']].drop_duplicates()\n",
    "    match_data = match_data.groupby('groupId')['winPlacePercPred'].mean().to_frame()\n",
    "    match_data = match_data.sort_values(by = 'winPlacePercPred', ascending = False).reset_index()\n",
    "    \n",
    "    winPlace = np.linspace(0, 1, num = int(num), endpoint = True).tolist()\n",
    "    winPlace = list(reversed(winPlace))\n",
    "    remove_lst = [] \n",
    "    for idx in indices :\n",
    "        remove_lst.append(winPlace[idx])\n",
    "        \n",
    "    for val in remove_lst : \n",
    "        if val in winPlace : \n",
    "            winPlace.remove(val)\n",
    "        \n",
    "    match_data['pred_winPlace'] = pd.Series(winPlace)\n",
    "    \n",
    "    pred_dict = match_data[['groupId', 'pred_winPlace']].set_index(['groupId']).to_dict()['pred_winPlace']\n",
    "    rank_dictionary.update(pred_dict)\n",
    "    \n",
    "    return  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25ac4797",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T13:11:52.062617Z",
     "iopub.status.busy": "2023-03-20T13:11:52.062167Z",
     "iopub.status.idle": "2023-03-20T13:11:52.069482Z",
     "shell.execute_reply": "2023-03-20T13:11:52.067096Z"
    },
    "papermill": {
     "duration": 0.018819,
     "end_time": "2023-03-20T13:11:52.072865",
     "exception": false,
     "start_time": "2023-03-20T13:11:52.054046",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c115a542",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T13:11:52.088247Z",
     "iopub.status.busy": "2023-03-20T13:11:52.087826Z",
     "iopub.status.idle": "2023-03-20T13:21:39.901536Z",
     "shell.execute_reply": "2023-03-20T13:21:39.899946Z"
    },
    "papermill": {
     "duration": 587.825065,
     "end_time": "2023-03-20T13:21:39.904554",
     "exception": false,
     "start_time": "2023-03-20T13:11:52.079489",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('/kaggle/input/pubg-finish-placement-prediction/train_V2.csv')\n",
    "test = pd.read_csv('/kaggle/input/pubg-finish-placement-prediction/test_V2.csv')\n",
    "\n",
    "test_post = test[['matchId', 'groupId']]\n",
    "\n",
    "train = preprocessing_func(train)\n",
    "test = preprocessing_func(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "def8f7fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T13:21:39.918799Z",
     "iopub.status.busy": "2023-03-20T13:21:39.918399Z",
     "iopub.status.idle": "2023-03-20T13:21:40.806021Z",
     "shell.execute_reply": "2023-03-20T13:21:40.804851Z"
    },
    "papermill": {
     "duration": 0.898124,
     "end_time": "2023-03-20T13:21:40.808962",
     "exception": false,
     "start_time": "2023-03-20T13:21:39.910838",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "matches_train = train['matchId'].unique()\n",
    "half = len(matches_train)//2\n",
    "certain_dictionary = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cd7be9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T13:21:40.823347Z",
     "iopub.status.busy": "2023-03-20T13:21:40.822911Z",
     "iopub.status.idle": "2023-03-20T13:55:28.644643Z",
     "shell.execute_reply": "2023-03-20T13:55:28.641768Z"
    },
    "papermill": {
     "duration": 2027.834083,
     "end_time": "2023-03-20T13:55:28.649166",
     "exception": false,
     "start_time": "2023-03-20T13:21:40.815083",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train1 progress : 0/23982 (0.0)%\n",
      "train1 progress : 500/23982 (2.085)%\n",
      "train1 progress : 1000/23982 (4.17)%\n",
      "train1 progress : 1500/23982 (6.255)%\n",
      "train1 progress : 2000/23982 (8.34)%\n",
      "train1 progress : 2500/23982 (10.424)%\n",
      "train1 progress : 3000/23982 (12.509)%\n",
      "train1 progress : 3500/23982 (14.594)%\n",
      "train1 progress : 4000/23982 (16.679)%\n",
      "train1 progress : 4500/23982 (18.764)%\n",
      "train1 progress : 5000/23982 (20.849)%\n",
      "train1 progress : 5500/23982 (22.934)%\n",
      "train1 progress : 6000/23982 (25.019)%\n",
      "train1 progress : 6500/23982 (27.104)%\n",
      "train1 progress : 7000/23982 (29.189)%\n",
      "train1 progress : 7500/23982 (31.273)%\n",
      "train1 progress : 8000/23982 (33.358)%\n",
      "train1 progress : 8500/23982 (35.443)%\n",
      "train1 progress : 9000/23982 (37.528)%\n",
      "train1 progress : 9500/23982 (39.613)%\n",
      "train1 progress : 10000/23982 (41.698)%\n",
      "train1 progress : 10500/23982 (43.783)%\n",
      "train1 progress : 11000/23982 (45.868)%\n",
      "train1 progress : 11500/23982 (47.953)%\n",
      "train1 progress : 12000/23982 (50.038)%\n",
      "train1 progress : 12500/23982 (52.122)%\n",
      "train1 progress : 13000/23982 (54.207)%\n",
      "train1 progress : 13500/23982 (56.292)%\n",
      "train1 progress : 14000/23982 (58.377)%\n",
      "train1 progress : 14500/23982 (60.462)%\n",
      "train1 progress : 15000/23982 (62.547)%\n",
      "train1 progress : 15500/23982 (64.632)%\n",
      "train1 progress : 16000/23982 (66.717)%\n",
      "train1 progress : 16500/23982 (68.802)%\n",
      "train1 progress : 17000/23982 (70.886)%\n",
      "train1 progress : 17500/23982 (72.971)%\n",
      "train1 progress : 18000/23982 (75.056)%\n",
      "train1 progress : 18500/23982 (77.141)%\n",
      "train1 progress : 19000/23982 (79.226)%\n",
      "train1 progress : 19500/23982 (81.311)%\n",
      "train1 progress : 20000/23982 (83.396)%\n",
      "train1 progress : 20500/23982 (85.481)%\n",
      "train1 progress : 21000/23982 (87.566)%\n",
      "train1 progress : 21500/23982 (89.651)%\n",
      "train1 progress : 22000/23982 (91.735)%\n",
      "train1 progress : 22500/23982 (93.82)%\n",
      "train1 progress : 23000/23982 (95.905)%\n",
      "train1 progress : 23500/23982 (97.99)%\n",
      "Memory usage of dataframe is 1719.65 MB\n",
      "Memory usage after optimization is: 434.21 MB\n",
      "Decreased by 74.8%\n"
     ]
    }
   ],
   "source": [
    "matches_train_1 = matches_train[:half]\n",
    "\n",
    "train_1 = train[train['matchId'].isin(matches_train_1)]\n",
    "\n",
    "final_dictionary = {} \n",
    "total = len(matches_train_1)\n",
    "i = 0\n",
    "\n",
    "for m in matches_train_1 :\n",
    "    try :\n",
    "        get_group_place(train_1, m)\n",
    "    except : \n",
    "        print('train1 error : ', m) \n",
    "    if i % 500 == 0 : \n",
    "        print(f'train1 progress : {i}/{total} ({np.round(i/total*100, 3)})%')\n",
    "    i += 1\n",
    "    \n",
    "winPlacePercPred_train = train_1['groupId'].map(final_dictionary)\n",
    "\n",
    "train_1 = reduce_mem_usage(train_1)\n",
    "train_1['winPlacePercPred'] = winPlacePercPred_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e84290b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T13:55:28.672477Z",
     "iopub.status.busy": "2023-03-20T13:55:28.671850Z",
     "iopub.status.idle": "2023-03-20T14:27:41.399021Z",
     "shell.execute_reply": "2023-03-20T14:27:41.397269Z"
    },
    "papermill": {
     "duration": 1932.744084,
     "end_time": "2023-03-20T14:27:41.402991",
     "exception": false,
     "start_time": "2023-03-20T13:55:28.658907",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train2 progress : 0/23983 (0.0)%\n",
      "train2 progress : 500/23983 (2.085)%\n",
      "train2 progress : 1000/23983 (4.17)%\n",
      "train2 progress : 1500/23983 (6.254)%\n",
      "train2 progress : 2000/23983 (8.339)%\n",
      "train2 progress : 2500/23983 (10.424)%\n",
      "train2 progress : 3000/23983 (12.509)%\n",
      "train2 progress : 3500/23983 (14.594)%\n",
      "train2 progress : 4000/23983 (16.678)%\n",
      "train2 progress : 4500/23983 (18.763)%\n",
      "train2 progress : 5000/23983 (20.848)%\n",
      "train2 progress : 5500/23983 (22.933)%\n",
      "train2 progress : 6000/23983 (25.018)%\n",
      "train2 progress : 6500/23983 (27.103)%\n",
      "train2 progress : 7000/23983 (29.187)%\n",
      "train2 progress : 7500/23983 (31.272)%\n",
      "train2 progress : 8000/23983 (33.357)%\n",
      "train2 progress : 8500/23983 (35.442)%\n",
      "train2 progress : 9000/23983 (37.527)%\n",
      "train2 progress : 9500/23983 (39.611)%\n",
      "train2 progress : 10000/23983 (41.696)%\n",
      "train2 progress : 10500/23983 (43.781)%\n",
      "train2 progress : 11000/23983 (45.866)%\n",
      "train2 progress : 11500/23983 (47.951)%\n",
      "train2 progress : 12000/23983 (50.035)%\n",
      "train2 progress : 12500/23983 (52.12)%\n",
      "train2 progress : 13000/23983 (54.205)%\n",
      "train2 progress : 13500/23983 (56.29)%\n",
      "train2 progress : 14000/23983 (58.375)%\n",
      "train2 progress : 14500/23983 (60.459)%\n",
      "train2 progress : 15000/23983 (62.544)%\n",
      "train2 progress : 15500/23983 (64.629)%\n",
      "train2 progress : 16000/23983 (66.714)%\n",
      "train2 progress : 16500/23983 (68.799)%\n",
      "train2 progress : 17000/23983 (70.884)%\n",
      "train2 progress : 17500/23983 (72.968)%\n",
      "train2 progress : 18000/23983 (75.053)%\n",
      "train2 progress : 18500/23983 (77.138)%\n",
      "train2 progress : 19000/23983 (79.223)%\n",
      "train2 progress : 19500/23983 (81.308)%\n",
      "train2 progress : 20000/23983 (83.392)%\n",
      "train2 progress : 20500/23983 (85.477)%\n",
      "train2 progress : 21000/23983 (87.562)%\n",
      "train2 progress : 21500/23983 (89.647)%\n",
      "train2 progress : 22000/23983 (91.732)%\n",
      "train2 progress : 22500/23983 (93.816)%\n",
      "train2 progress : 23000/23983 (95.901)%\n",
      "train2 progress : 23500/23983 (97.986)%\n",
      "Memory usage of dataframe is 1673.11 MB\n",
      "Memory usage after optimization is: 422.46 MB\n",
      "Decreased by 74.8%\n"
     ]
    }
   ],
   "source": [
    "matches_train_2 = matches_train[half:]\n",
    "\n",
    "train_2 = train[train['matchId'].isin(matches_train_2)]\n",
    "\n",
    "final_dictionary = {} \n",
    "total = len(matches_train_2)\n",
    "i = 0\n",
    "\n",
    "for m in matches_train_2 :\n",
    "    try :\n",
    "        get_group_place(train_2, m)\n",
    "    except : \n",
    "        print('train2 error : ', m)\n",
    "    if i % 500 == 0 : \n",
    "        print(f'train2 progress : {i}/{total} ({np.round(i/total*100, 3)})%')\n",
    "    i += 1\n",
    "    \n",
    "winPlacePercPred_train = train_2['groupId'].map(final_dictionary)\n",
    "\n",
    "train_2 = reduce_mem_usage(train_2)\n",
    "train_2['winPlacePercPred'] = winPlacePercPred_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2657bc2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T14:27:41.431836Z",
     "iopub.status.busy": "2023-03-20T14:27:41.431368Z",
     "iopub.status.idle": "2023-03-20T14:51:31.695352Z",
     "shell.execute_reply": "2023-03-20T14:51:31.693467Z"
    },
    "papermill": {
     "duration": 1430.282253,
     "end_time": "2023-03-20T14:51:31.698785",
     "exception": false,
     "start_time": "2023-03-20T14:27:41.416532",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress : 0/20556 (0.0)%\n",
      "progress : 1000/20556 (5.0)%\n",
      "progress : 2000/20556 (10.0)%\n",
      "progress : 3000/20556 (15.0)%\n",
      "progress : 4000/20556 (19.0)%\n",
      "progress : 5000/20556 (24.0)%\n",
      "progress : 6000/20556 (29.0)%\n",
      "progress : 7000/20556 (34.0)%\n",
      "progress : 8000/20556 (39.0)%\n",
      "progress : 9000/20556 (44.0)%\n",
      "progress : 10000/20556 (49.0)%\n",
      "progress : 11000/20556 (54.0)%\n",
      "progress : 12000/20556 (58.0)%\n",
      "progress : 13000/20556 (63.0)%\n",
      "progress : 14000/20556 (68.0)%\n",
      "progress : 15000/20556 (73.0)%\n",
      "progress : 16000/20556 (78.0)%\n",
      "progress : 17000/20556 (83.0)%\n",
      "progress : 18000/20556 (88.0)%\n",
      "progress : 19000/20556 (92.0)%\n",
      "progress : 20000/20556 (97.0)%\n",
      "Memory usage of dataframe is 1446.14 MB\n",
      "Memory usage after optimization is: 354.16 MB\n",
      "Decreased by 75.5%\n"
     ]
    }
   ],
   "source": [
    "matches_test = test['matchId'].unique()\n",
    "\n",
    "final_dictionary = {} \n",
    "total = len(matches_test)\n",
    "i = 0\n",
    "\n",
    "for m in matches_test :\n",
    "    try :\n",
    "        get_group_place(test, m)\n",
    "    except : \n",
    "        print('error : ', m)\n",
    "    if i % 1000 == 0 : \n",
    "        print(f'progress : {i}/{total} ({np.round(i/total*100)})%')\n",
    "    i += 1 \n",
    "    \n",
    "winPlacePercPred_test = test['groupId'].map(final_dictionary)\n",
    "\n",
    "test = reduce_mem_usage(test)\n",
    "test['winPlacePercPred'] = winPlacePercPred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a866321c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T14:51:31.731631Z",
     "iopub.status.busy": "2023-03-20T14:51:31.730871Z",
     "iopub.status.idle": "2023-03-20T14:51:37.009826Z",
     "shell.execute_reply": "2023-03-20T14:51:37.008634Z"
    },
    "papermill": {
     "duration": 5.298869,
     "end_time": "2023-03-20T14:51:37.012680",
     "exception": false,
     "start_time": "2023-03-20T14:51:31.713811",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.concat([train_1, train_2], axis = 0, ignore_index = True)\n",
    "\n",
    "train['winPlacePercPred'] = [(2*x+y)/3 if z in ['solo', 'solo-fpp'] else x  \\\n",
    "                             for x, y, z in zip(train['winPlacePercPred'], train['walkDistance_rank'], train['matchType'])]\n",
    "\n",
    "test['winPlacePercPred'] = [(2*x+y)/3 if z in ['solo', 'solo-fpp'] else x\\\n",
    "                            for x, y, z in zip(test['winPlacePercPred'], test['walkDistance_rank'], test['matchType'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "827a35fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T14:51:37.046610Z",
     "iopub.status.busy": "2023-03-20T14:51:37.046113Z",
     "iopub.status.idle": "2023-03-20T14:51:57.126601Z",
     "shell.execute_reply": "2023-03-20T14:51:57.124810Z"
    },
    "papermill": {
     "duration": 20.101184,
     "end_time": "2023-03-20T14:51:57.129989",
     "exception": false,
     "start_time": "2023-03-20T14:51:37.028805",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = train.drop(['winPlacePerc'], axis = 1) \n",
    "y = train['winPlacePerc']\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y,\n",
    "                                                      test_size = 0.1,\n",
    "                                                      stratify = X['matchType'],\n",
    "                                                      random_state = 1234)\n",
    "\n",
    "X_train.drop(['Id', 'groupId', 'matchId'], axis = 1, inplace = True)\n",
    "X_valid.drop(['Id', 'groupId', 'matchId'], axis = 1, inplace = True)\n",
    "test.drop(['Id', 'groupId', 'matchId'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc30daf2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T14:51:57.161832Z",
     "iopub.status.busy": "2023-03-20T14:51:57.161410Z",
     "iopub.status.idle": "2023-03-20T14:52:06.227729Z",
     "shell.execute_reply": "2023-03-20T14:52:06.226639Z"
    },
    "papermill": {
     "duration": 9.085881,
     "end_time": "2023-03-20T14:52:06.230773",
     "exception": false,
     "start_time": "2023-03-20T14:51:57.144892",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse = False)\n",
    "\n",
    "# fitting\n",
    "encoder.fit(X_train[['matchType']])\n",
    "onehot_colnames = [col for col in encoder.categories_[0]]\n",
    "\n",
    "\n",
    "# train\n",
    "onehot = encoder.transform(X_train[['matchType']])\n",
    "onehot = pd.DataFrame(onehot)\n",
    "onehot.columns = onehot_colnames\n",
    "X_train = pd.concat([X_train.reset_index(drop = True), onehot], axis = 1)\n",
    "X_train.drop('matchType', axis = 1, inplace = True)\n",
    "\n",
    "# valid\n",
    "onehot = encoder.transform(X_valid[['matchType']])\n",
    "onehot = pd.DataFrame(onehot)\n",
    "onehot.columns = onehot_colnames\n",
    "X_valid = pd.concat([X_valid.reset_index(drop = True), onehot], axis = 1)\n",
    "X_valid.drop('matchType', axis = 1, inplace = True)\n",
    "\n",
    "# test\n",
    "onehot = encoder.transform(test[['matchType']])\n",
    "onehot = pd.DataFrame(onehot)\n",
    "onehot.columns = onehot_colnames\n",
    "test = pd.concat([test.reset_index(drop = True), onehot], axis = 1)\n",
    "test.drop('matchType', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f72584be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T14:52:06.261238Z",
     "iopub.status.busy": "2023-03-20T14:52:06.260649Z",
     "iopub.status.idle": "2023-03-20T14:52:07.240430Z",
     "shell.execute_reply": "2023-03-20T14:52:07.239235Z"
    },
    "papermill": {
     "duration": 0.998884,
     "end_time": "2023-03-20T14:52:07.243929",
     "exception": false,
     "start_time": "2023-03-20T14:52:06.245045",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cols = ['winPlacePercPred', 'matchDuration', 'groupKillplace', 'numGroups',\n",
    "        'killPlace', 'walkDistance_rank', 'swimDistance_rank', 'walkDistance_max', \n",
    "        'walkDistance_mean', 'kills_rank', 'headshotKills_rank', 'maxPlace', \n",
    "        'assists_rank', 'teamKills_rank', 'killStreaks_rank', 'longestKill_mean', 'damageDealt_mean',\n",
    "        'playersJoined', 'damageDealt_max', 'longestKill_max', 'longestKill_rank',\n",
    "        'boosts_rank', 'revives_rank', 'killStreaks_mean', 'weaponsAcquired_mean',\n",
    "        'weaponsAcquired_max', 'heals_rank', 'totalDistance', 'boosts_mean',\n",
    "         'kills_mean', 'groupBoostsAndHeals', 'weaponsAcquired_rank', 'playersInGroup',\n",
    "         'heals_mean', 'rideDistance', 'walkDistance', 'DBNOs_rank', 'roadKills_rank',\n",
    "         'DBNOs_mean', 'damageDealt_rank', 'assists_mean', 'assists_mean_rank', 'boosts_mean_rank',\n",
    "         'damageDealt_mean_rank', 'DBNOs_mean_rank', 'headshotKills_mean_rank', 'heals_mean_rank',\n",
    "         'kills_mean_rank', 'killStreaks_mean_rank', 'longestKill_mean_rank', 'revives_mean_rank',\n",
    "         'roadKills_mean_rank', 'swimDistance_mean_rank', 'teamKills_mean_rank', 'walkDistance_mean_rank',\n",
    "         'weaponsAcquired_mean_rank', 'walk/kills_rank', 'kills/walk_rank']\n",
    "\n",
    "X_train = X_train[cols]\n",
    "X_valid = X_valid[cols]\n",
    "test = test[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cfd20ffe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T14:52:07.283661Z",
     "iopub.status.busy": "2023-03-20T14:52:07.282574Z",
     "iopub.status.idle": "2023-03-20T14:52:07.289619Z",
     "shell.execute_reply": "2023-03-20T14:52:07.287497Z"
    },
    "papermill": {
     "duration": 0.030056,
     "end_time": "2023-03-20T14:52:07.294256",
     "exception": false,
     "start_time": "2023-03-20T14:52:07.264200",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mae(y_test, y_pred) : \n",
    "    return np.mean(np.abs(y_test - y_pred))\n",
    "\n",
    "def neg_mae(y_test, y_pred) : \n",
    "    return -np.mean(np.abs(y_test - y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "34348643",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T14:52:07.333305Z",
     "iopub.status.busy": "2023-03-20T14:52:07.332468Z",
     "iopub.status.idle": "2023-03-21T00:13:19.402485Z",
     "shell.execute_reply": "2023-03-21T00:13:19.397735Z"
    },
    "papermill": {
     "duration": 33672.109438,
     "end_time": "2023-03-21T00:13:19.421550",
     "exception": false,
     "start_time": "2023-03-20T14:52:07.312112",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... | learni... | max_depth | min_da... | n_esti... | num_le... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=796, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=796\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m-0.01993 \u001b[0m | \u001b[0m0.5958   \u001b[0m | \u001b[0m0.08111  \u001b[0m | \u001b[0m7.751    \u001b[0m | \u001b[0m796.1    \u001b[0m | \u001b[0m7.91e+03 \u001b[0m | \u001b[0m345.3    \u001b[0m | \u001b[0m0.6382   \u001b[0m |\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=390, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=390\n",
      "| \u001b[95m2        \u001b[0m | \u001b[95m-0.0183  \u001b[0m | \u001b[95m0.9009   \u001b[0m | \u001b[95m0.09791  \u001b[0m | \u001b[95m9.504    \u001b[0m | \u001b[95m389.9    \u001b[0m | \u001b[95m5.259e+03\u001b[0m | \u001b[95m715.1    \u001b[0m | \u001b[95m0.8564   \u001b[0m |\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=63, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=63\n",
      "| \u001b[95m3        \u001b[0m | \u001b[95m-0.01826 \u001b[0m | \u001b[95m0.6851   \u001b[0m | \u001b[95m0.07806  \u001b[0m | \u001b[95m8.012    \u001b[0m | \u001b[95m63.08    \u001b[0m | \u001b[95m7.842e+03\u001b[0m | \u001b[95m894.4    \u001b[0m | \u001b[95m0.6824   \u001b[0m |\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=936, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=936\n",
      "| \u001b[0m4        \u001b[0m | \u001b[0m-0.02069 \u001b[0m | \u001b[0m0.8077   \u001b[0m | \u001b[0m0.05377  \u001b[0m | \u001b[0m7.475    \u001b[0m | \u001b[0m936.5    \u001b[0m | \u001b[0m6.688e+03\u001b[0m | \u001b[0m457.5    \u001b[0m | \u001b[0m0.8944   \u001b[0m |\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=464, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=464\n",
      "| \u001b[0m5        \u001b[0m | \u001b[0m-0.01881 \u001b[0m | \u001b[0m0.6584   \u001b[0m | \u001b[0m0.0784   \u001b[0m | \u001b[0m9.477    \u001b[0m | \u001b[0m464.4    \u001b[0m | \u001b[0m8.12e+03 \u001b[0m | \u001b[0m229.4    \u001b[0m | \u001b[0m0.8521   \u001b[0m |\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=945, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=945\n",
      "| \u001b[0m6        \u001b[0m | \u001b[0m-0.02102 \u001b[0m | \u001b[0m0.5265   \u001b[0m | \u001b[0m0.05674  \u001b[0m | \u001b[0m9.267    \u001b[0m | \u001b[0m945.5    \u001b[0m | \u001b[0m3.056e+03\u001b[0m | \u001b[0m489.0    \u001b[0m | \u001b[0m0.6486   \u001b[0m |\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=66, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=66\n",
      "| \u001b[95m7        \u001b[0m | \u001b[95m-0.01638 \u001b[0m | \u001b[95m0.8435   \u001b[0m | \u001b[95m0.09444  \u001b[0m | \u001b[95m9.576    \u001b[0m | \u001b[95m66.13    \u001b[0m | \u001b[95m5.313e+03\u001b[0m | \u001b[95m950.5    \u001b[0m | \u001b[95m0.7254   \u001b[0m |\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=997, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=997\n",
      "| \u001b[0m8        \u001b[0m | \u001b[0m-0.02101 \u001b[0m | \u001b[0m0.5046   \u001b[0m | \u001b[0m0.09675  \u001b[0m | \u001b[0m8.175    \u001b[0m | \u001b[0m997.2    \u001b[0m | \u001b[0m3.32e+03 \u001b[0m | \u001b[0m691.7    \u001b[0m | \u001b[0m0.7392   \u001b[0m |\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=232, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=232\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m-0.01767 \u001b[0m | \u001b[0m0.6471   \u001b[0m | \u001b[0m0.06183  \u001b[0m | \u001b[0m9.712    \u001b[0m | \u001b[0m231.7    \u001b[0m | \u001b[0m8.639e+03\u001b[0m | \u001b[0m995.3    \u001b[0m | \u001b[0m0.5311   \u001b[0m |\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=361, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=361\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m-0.02112 \u001b[0m | \u001b[0m0.8864   \u001b[0m | \u001b[0m0.06229  \u001b[0m | \u001b[0m9.343    \u001b[0m | \u001b[0m361.3    \u001b[0m | \u001b[0m983.0    \u001b[0m | \u001b[0m119.7    \u001b[0m | \u001b[0m0.9271   \u001b[0m |\n",
      "=============================================================================================================\n"
     ]
    }
   ],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "import lightgbm as lgb \n",
    "\n",
    "params_bounds = {\n",
    "    'n_estimators' : (500, 10000),\n",
    "    'learning_rate' : (0.05, 0.1),\n",
    "    'max_depth': (6, 10),\n",
    "    'subsample' : (0.5, 1),\n",
    "    'colsample_bytree': (0.5, 1),\n",
    "    'min_data_in_leaf': (50, 1000),\n",
    "    'num_leaves': (100, 1000),\n",
    "}\n",
    "\n",
    "def lgbm_bo(n_estimators, learning_rate, max_depth, subsample,\n",
    "            colsample_bytree, min_data_in_leaf, num_leaves):\n",
    "    params = {\n",
    "        'n_estimators' : int(round(n_estimators)),\n",
    "        'learning_rate' : max(0, learning_rate),\n",
    "        'max_depth': int(round(max_depth)),\n",
    "        'subsample' : max(0, subsample),\n",
    "        'colsample_bytree': max(0, colsample_bytree),\n",
    "        'min_data_in_leaf': int(round(min_data_in_leaf)),\n",
    "        'num_leaves': int(round(num_leaves)),\n",
    "    }\n",
    "    model = lgb.LGBMRegressor(**params,\n",
    "                              metric = 'mae')\n",
    "    \n",
    "    model.fit(X_train,y_train)\n",
    "    score = neg_mae(y_valid, model.predict(X_valid))\n",
    "    \n",
    "    return score\n",
    "\n",
    "BO_lgbm = BayesianOptimization(f = lgbm_bo, \n",
    "                               pbounds = params_bounds,\n",
    "                               random_state = 1234)\n",
    "\n",
    "BO_lgbm.maximize(init_points = 5, n_iter = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "72645d57",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T00:13:19.461049Z",
     "iopub.status.busy": "2023-03-21T00:13:19.459922Z",
     "iopub.status.idle": "2023-03-21T00:13:19.478816Z",
     "shell.execute_reply": "2023-03-21T00:13:19.477461Z"
    },
    "papermill": {
     "duration": 0.045331,
     "end_time": "2023-03-21T00:13:19.482751",
     "exception": false,
     "start_time": "2023-03-21T00:13:19.437420",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.8435149227601455,\n",
       " 'learning_rate': 0.09443955225184758,\n",
       " 'max_depth': 10,\n",
       " 'min_data_in_leaf': 66,\n",
       " 'n_estimators': 5313,\n",
       " 'num_leaves': 951,\n",
       " 'subsample': 0.7253512882972104,\n",
       " 'metric': 'mae'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = BO_lgbm.max['params']\n",
    "best_params['max_depth'] = int(np.round(best_params['max_depth']))\n",
    "best_params['min_data_in_leaf'] = int(np.round(best_params['min_data_in_leaf']))\n",
    "best_params['n_estimators'] = int(np.round(best_params['n_estimators']))\n",
    "best_params['num_leaves'] = int(np.round(best_params['num_leaves']))\n",
    "best_params['metric'] = 'mae'\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e2cb88b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T00:13:19.518855Z",
     "iopub.status.busy": "2023-03-21T00:13:19.517931Z",
     "iopub.status.idle": "2023-03-21T00:13:19.523309Z",
     "shell.execute_reply": "2023-03-21T00:13:19.522446Z"
    },
    "papermill": {
     "duration": 0.026879,
     "end_time": "2023-03-21T00:13:19.526022",
     "exception": false,
     "start_time": "2023-03-21T00:13:19.499143",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# model = lgb.LGBMRegressor(**best_params,\n",
    "#                           n_jobs = -1,\n",
    "#                           random_state = 1234)\n",
    "\n",
    "# model.fit(X_train, y_train, \n",
    "#           eval_set = [(X_train, y_train),\n",
    "#                       (X_valid, y_valid)],\n",
    "#           verbose = 100, \n",
    "#           early_stopping_rounds = 100) \n",
    "# lgb.plot_metric(model, ylim = (0.005, 0.025))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dcf22a22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T00:13:19.560270Z",
     "iopub.status.busy": "2023-03-21T00:13:19.559437Z",
     "iopub.status.idle": "2023-03-21T00:13:19.564817Z",
     "shell.execute_reply": "2023-03-21T00:13:19.563749Z"
    },
    "papermill": {
     "duration": 0.024957,
     "end_time": "2023-03-21T00:13:19.567151",
     "exception": false,
     "start_time": "2023-03-21T00:13:19.542194",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt \n",
    "# fig, ax = plt.subplots(figsize = (10, 20))\n",
    "# lgb.plot_importance(model, ax = ax)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "58d9a6d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T00:13:19.601233Z",
     "iopub.status.busy": "2023-03-21T00:13:19.600821Z",
     "iopub.status.idle": "2023-03-21T00:13:19.605508Z",
     "shell.execute_reply": "2023-03-21T00:13:19.604336Z"
    },
    "papermill": {
     "duration": 0.025089,
     "end_time": "2023-03-21T00:13:19.607824",
     "exception": false,
     "start_time": "2023-03-21T00:13:19.582735",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pred = model.predict(test)\n",
    "\n",
    "# test = pd.concat([test, test_post], axis = 1)\n",
    "# test['winPlacePercPred'] = pred\n",
    "# test_post_matches = test['matchId'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "abddc282",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T00:13:19.641001Z",
     "iopub.status.busy": "2023-03-21T00:13:19.640613Z",
     "iopub.status.idle": "2023-03-21T00:13:19.645316Z",
     "shell.execute_reply": "2023-03-21T00:13:19.644140Z"
    },
    "papermill": {
     "duration": 0.024202,
     "end_time": "2023-03-21T00:13:19.647553",
     "exception": false,
     "start_time": "2023-03-21T00:13:19.623351",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# rank_dictionary = {} \n",
    "# total = len(test_post_matches)\n",
    "# i = 0\n",
    "\n",
    "# for tpm in test_post_matches : \n",
    "#     try :\n",
    "#         postprocessing_func(test, tpm)\n",
    "#     except : \n",
    "#         print('error : ', tpm)\n",
    "#     if i % 1000 == 0 : \n",
    "#         print(f'progress : {i}/{total} ({np.round(i/total*100)})%')\n",
    "#     i += 1 \n",
    "# winPlacePercPred_postprocessing = test['groupId'].map(rank_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "777ce4ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T00:13:19.681427Z",
     "iopub.status.busy": "2023-03-21T00:13:19.680679Z",
     "iopub.status.idle": "2023-03-21T00:13:19.684849Z",
     "shell.execute_reply": "2023-03-21T00:13:19.683984Z"
    },
    "papermill": {
     "duration": 0.023341,
     "end_time": "2023-03-21T00:13:19.687029",
     "exception": false,
     "start_time": "2023-03-21T00:13:19.663688",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# submission = pd.read_csv('/kaggle/input/pubg-finish-placement-prediction/sample_submission_V2.csv')\n",
    "# submission['winPlacePerc'] = winPlacePercPred_postprocessing\n",
    "\n",
    "# if submission.isnull().sum().sum() > 0 : \n",
    "#     print('error')\n",
    "#     submission = submission.fillna(0, inplace = True)\n",
    "# submission.to_csv('submission.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 39702.277812,
   "end_time": "2023-03-21T00:13:22.596333",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-03-20T13:11:40.318521",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
